{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJKrNuBTkgqu"
   },
   "source": [
    " # CAM \n",
    "\n",
    "This notebook is based on code found at: \n",
    "\n",
    "https://snappishproductions.com/blog/2018/01/03/class-activation-mapping-in-pytorch.html.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qt_o1xCa46u0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "from matplotlib.pyplot import imshow\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "import torch\n",
    "import numpy as np\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjEPGP3bgjp1"
   },
   "source": [
    "## Import\n",
    "Import image that we want to classify. Based on code from SML course UU - lab exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "_ql3U3nphaYd",
    "outputId": "49202763-d183-4e24-8595-8fe855424838"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Felis_catus-cat_on_snow.jpg/640px-Felis_catus-cat_on_snow.jpg'\n",
    "\n",
    "lighthouse_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse_original.jpg?raw=true'\n",
    "lighthouse_90deg_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse_90deg.jpg?raw=true'\n",
    "lighthouse_blur_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse_blur.jpg?raw=true'\n",
    "lighthouse_highpass_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse_highpass.jpg?raw=true'\n",
    "lighthouse_mix_channel_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse_mix_channel.jpg?raw=true'\n",
    "lighthouse_noise_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse_noise.jpg?raw=true'\n",
    "lighthouse_equalized_url = 'https://github.com/Falk0/latex_master1_semester2/blob/main/deep_learning_for_image_analysis/figures/assignment_4/lighthouse%20equalized.jpg?raw=true'\n",
    "\n",
    "lighthouse_url_list = [\n",
    "    lighthouse_url,\n",
    "    lighthouse_90deg_url,\n",
    "    lighthouse_blur_url,\n",
    "    lighthouse_highpass_url,\n",
    "    lighthouse_mix_channel_url,\n",
    "    lighthouse_noise_url,\n",
    "    lighthouse_equalized_url   \n",
    "]\n",
    "\n",
    "description = ['Original', '90deg', 'Gaussian blur', 'Highpass filtered', 'Mixed color channels', 'Noise', 'Hist.equalized']\n",
    "\n",
    "lighthouse_image_list = []\n",
    "for i in range(len(lighthouse_url_list)):\n",
    "    \n",
    "    try:\n",
    "        with Image.open(urlopen(lighthouse_url_list[i])) as im:\n",
    "            # The following fixes some problems when loading images:\n",
    "            # https://stackoverflow.com/a/64598016\n",
    "            lighthouse_image_list.append(im.convert(\"RGB\"))\n",
    "    except (URLError, OSError):\n",
    "        print(\"please provide a valid URL or local path\")\n",
    "\n",
    "\n",
    " \n",
    "print(f\"{lighthouse_image_list[3].mode} image of size {lighthouse_image_list[3].size}\")\n",
    "plt.imshow(np.asarray(lighthouse_image_list[3]))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store class names in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL of the raw text file on GitHub\n",
    "class_name = {}\n",
    "\n",
    "# Define the URL of the raw text file on GitHub\n",
    "url = 'https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt'\n",
    "\n",
    "try:\n",
    "    # Open the URL and read the contents of the file\n",
    "    with urlopen(url) as response:\n",
    "        text = response.read().decode('utf-8')\n",
    "        text = text.replace('{', '')\n",
    "        text = text.replace('}', '')\n",
    "\n",
    "        for line in text.splitlines():\n",
    "            key, value = line.split(':')\n",
    "            key = int(key)\n",
    "    \n",
    "            if value.count(',') >= 2:\n",
    "                value = value.replace(',', '\\n', 1)\n",
    "            # remove last , if present\n",
    "            if value.endswith(','):\n",
    "                value = value[:-1]\n",
    "\n",
    "            class_name[key] = value.replace(\"'\", \"\")\n",
    "\n",
    "except URLError as e:\n",
    "    print(\"please provide a valid URL or local path\")\n",
    "\n",
    "# set  beacon, lighthouse, beacon light, pharos to lighthouse for less printing\n",
    "class_name[437] = 'lighthouse'\n",
    "\n",
    "# print some random class names\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the 3 images for attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandal_url = \"https://raw.githubusercontent.com/Okrash0/Explainable-Artificial-Intelligence/main/fig/sandal.jpg\"\n",
    "toilet_url = \"https://raw.githubusercontent.com/Okrash0/Explainable-Artificial-Intelligence/main/fig/toilet.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_list = [sandal_url, toilet_url]\n",
    "image_list = []\n",
    "\n",
    "for i in range(len(image_url_list)):\n",
    "    \n",
    "    try:\n",
    "        with Image.open(urlopen(image_url_list[i])) as im:\n",
    "            # The following fixes some problems when loading images:\n",
    "            # https://stackoverflow.com/a/64598016\n",
    "            image_list.append(im.convert(\"RGB\"))\n",
    "    except (URLError, OSError):\n",
    "        print(\"please provide a valid URL or local path\")\n",
    "\n",
    "image_name_list = [\"toilet\", \"sandal\", \"lighthouse\"]\n",
    "\n",
    "image_list.append(lighthouse_image_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images in subplots \n",
    "fig, axs = plt.subplots(1, len(image_list))\n",
    "for i in range(len(image_list)):\n",
    "    axs[i].imshow(np.asarray(image_list[i]))\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_1(image_list, mode=None):\n",
    "    fig, axs = plt.subplots(1, len(image_list))\n",
    "    for i in range(len(image_list)):\n",
    "        axs[i].imshow(np.asarray(image_list[i]), cmap=mode)\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_filter(image, angle=90):\n",
    "    return image.rotate(angle)\n",
    "\n",
    "def blur_filter(image, radius=2):\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "\n",
    "def gaussian_noise_filter(image):\n",
    "    # convert to numpy array\n",
    "    image = np.asarray(image)\n",
    "    row, col, ch = image.shape\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var**0.9\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    gauss = gauss.reshape(row, col, ch)\n",
    "    # convert image to float in range 0-1\n",
    "    noise = gauss * 255\n",
    "\n",
    "    # add noise to image and round if down or up if final value is 0 or 255\n",
    "    noise = image + noise\n",
    "    noise = np.where(noise < 0, 0, noise)\n",
    "    noise = np.where(noise > 255, 255, noise)\n",
    "\n",
    "    # convert back to PIL image\n",
    "    return Image.fromarray(noise.astype('uint8'), 'RGB')\n",
    "\n",
    "def mix_color_filter(image, mode=1):\n",
    "    # Split the color channels\n",
    "    r, g, b = image.split()\n",
    "\n",
    "    # Mix the color channels\n",
    "    if mode == 1:\n",
    "        return Image.merge(\"RGB\", (b, g, r))\n",
    "    elif mode == 2:\n",
    "        return Image.merge(\"RGB\", (r, b, g))\n",
    "    elif mode == 3:\n",
    "        return Image.merge(\"RGB\", (g, r, b))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the filters\n",
    "Just for testing right now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_list[0])\n",
    "\n",
    "rotated_list = []\n",
    "for i in range(len(image_list)):\n",
    "    rotated_list.append(rotate_filter(image_list[i]))\n",
    "\n",
    "plot_images_1(rotated_list)\n",
    "\n",
    "gause_list = []\n",
    "for i in range(len(image_list)):\n",
    "    gause_list.append(blur_filter(image_list[i], 10))\n",
    "\n",
    "plot_images_1(gause_list)\n",
    "\n",
    "noise_list = []\n",
    "for i in range(len(image_list)):\n",
    "    noise_list.append(gaussian_noise_filter(image_list[i]))\n",
    "\n",
    "plot_images_1(noise_list)\n",
    "\n",
    "mix_list = []\n",
    "for i in range(len(image_list)):\n",
    "    mix_list.append(mix_color_filter(image_list[i], 2))\n",
    "\n",
    "plot_images_1(mix_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM7ZAKaYfrbM"
   },
   "source": [
    "## Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uN1WMN_Pfqo6"
   },
   "outputs": [],
   "source": [
    "# Imagenet mean/std\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Preprocessing - scale to 224x224 for model, convert to tensor, \n",
    "# and normalize to -1..1 with mean/std for ImageNet\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224,224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "display_transform = transforms.Compose([\n",
    "   transforms.Resize((224,224))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5KGy2OHf32D"
   },
   "outputs": [],
   "source": [
    "lighthouse_tensors = []\n",
    "for i in range(len(lighthouse_image_list)):\n",
    "    lighthouse_tensors.append(preprocess(lighthouse_image_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors = []\n",
    "for i in range(len(image_list)):\n",
    "    image_tensors.append(preprocess(image_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXk-tjj6f9aB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLVfAF50f9g4"
   },
   "outputs": [],
   "source": [
    "prediction_var_list = []\n",
    "for i in range(len(lighthouse_image_list)):\n",
    "    prediction_var_list.append(Variable((lighthouse_tensors[i].unsqueeze(0)), requires_grad=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_var_list_image = []\n",
    "for i in range(len(image_list)):\n",
    "    prediction_var_list_image.append(Variable((image_tensors[i].unsqueeze(0)), requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4lRTXcof9z3"
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2VfgK7Gf96h",
    "outputId": "c584d4cf-5561-4a56-f2f2-c848851a63a9"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcAJJFPXf-Ar"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGLe8iXvf-Ib"
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GJnqBL7g8Jn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbDYUn9kg8cy"
   },
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy()\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHLzITopg8lY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mez3XwtLg8qV"
   },
   "outputs": [],
   "source": [
    "final_layer = model._modules.get('layer4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFGB1aNqg8vX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rWp6bYshJwF"
   },
   "outputs": [],
   "source": [
    "activated_features = SaveFeatures(final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emrz15euip9g"
   },
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bH_PffMipOb",
    "outputId": "f0f26073-491e-43fd-8299-06cc61eac6b5"
   },
   "outputs": [],
   "source": [
    "pred_probabilities_list = []\n",
    "\n",
    "for i in range(len(lighthouse_tensors)):\n",
    "    prediction = model(prediction_var_list[i])\n",
    "    pred_probabilities_list.append(F.softmax(prediction).data.squeeze())\n",
    "    activated_features.remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYCLrRA2irGl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V13HFpOUiqei",
    "outputId": "7b71c8bb-3c55-4037-d475-2235a00d96b4"
   },
   "outputs": [],
   "source": [
    "for i in range(len(lighthouse_tensors)):\n",
    "    topk(pred_probabilities_list[i],1)\n",
    "    print(topk(pred_probabilities_list[i],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BKwcMNziqkq"
   },
   "source": [
    " https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
    " \n",
    "437: 'beacon, lighthouse, beacon light, pharos',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDoceAOTiqqS"
   },
   "outputs": [],
   "source": [
    "def getCAM(feature_conv, weight_fc, class_idx):\n",
    "    _, nc, h, w = feature_conv.shape\n",
    "    cam = weight_fc[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    return [cam_img]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLl34Ylki0zi"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WsLUeMGi05H"
   },
   "outputs": [],
   "source": [
    "weight_softmax_params = list(model._modules.get('fc').parameters())\n",
    "weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6b2Zc9Gi1Ap"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr-JIa7ji1G9"
   },
   "outputs": [],
   "source": [
    "weight_softmax_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruhzX4SnjCsa"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxMoQKnUjCyj",
    "outputId": "63604dc1-f0ec-4439-96a7-8cb58ce63410"
   },
   "outputs": [],
   "source": [
    "overlay_list = []\n",
    "class_list = []\n",
    "for i in range(len(lighthouse_tensors)):\n",
    "    class_idx = topk(pred_probabilities_list[i],1)[1].int()\n",
    "    overlay_list.append(getCAM(activated_features.features, weight_softmax, class_idx))\n",
    "    class_list.append(class_idx)\n",
    "    print(topk(pred_probabilities_list[i],1))\n",
    "    activated_features.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlay_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUiQ55bjjGT0"
   },
   "source": [
    "## Plot heatmap of predicted class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(overlay_images, titles, save_plot=False):\n",
    "    \"\"\"plot heatmap of images with titles\n",
    "    Args: \n",
    "        overlay_images: list of overlay images\n",
    "        titles: list of titles\n",
    "        save_plot: bool, save plot or not\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(overlay_images)\n",
    "    _, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
    "\n",
    "    for i in range(n):\n",
    "        if n == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "        ax.imshow(overlay_images[i][0], alpha=0.5, cmap='jet')\n",
    "        ax.set_title(titles[i].item())\n",
    "        ax.axis('off')\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig('plot.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images(images, titles, save_plot=False):\n",
    "    \"\"\"plot images with titles\n",
    "    Args:\n",
    "        images: list of images\n",
    "        titles: list of titles\n",
    "        save_plot: bool, save plot or not\n",
    "\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
    "\n",
    "    for i in range(n):\n",
    "        if n == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title(titles[i])\n",
    "        ax.axis('off')\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig('plot.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images_overlay(images, tensor, overlay_list, titles, save_plot=False):\n",
    "    \"\"\"plot images with titles and overlay\n",
    "    Args:\n",
    "        images: list of images\n",
    "        tensor: list of images\n",
    "        overlay_list: list of overlay images\n",
    "        titles: list of tensors with class index\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
    "\n",
    "    for i in range(n):\n",
    "        if n == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "        ax.imshow(display_transform(images[i]))\n",
    "        ax.imshow(skimage.transform.resize(\n",
    "            overlay_list[i][0], tensor[i].shape[1:3]), alpha=0.5, cmap='jet')\n",
    "        ax.set_title(class_name[titles[i].item()])\n",
    "        ax.axis('off')\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig('plot.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(overlay_list, class_list)\n",
    "plot_images(lighthouse_image_list, description)\n",
    "plot_images_overlay(lighthouse_image_list, lighthouse_tensors, overlay_list, class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjkSsDerjGhH"
   },
   "source": [
    " 437: 'beacon, lighthouse, beacon light, pharos',\n",
    " \n",
    " 972: 'cliff, drop, drop-off',\n",
    " \n",
    " 646: 'maze, labyrinth',\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "3eKxDPcxjGpi",
    "outputId": "81e54dda-1d19-4cbd-9361-8efda31789e8"
   },
   "outputs": [],
   "source": [
    "imshow(display_transform(lighthouse_image_list[3]))\n",
    "imshow(skimage.transform.resize(overlay_list[3][0], lighthouse_tensors[0].shape[1:3]), alpha=0.5, cmap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW7fcfvRjSBr"
   },
   "source": [
    "## Plot heatmap of second predected class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ol02niNEjQvP"
   },
   "outputs": [],
   "source": [
    "overlay_list_sec = []\n",
    "class_list_sec = []\n",
    "for i in range(len(lighthouse_tensors)):\n",
    "    class_idx = topk(pred_probabilities_list[i],2)[1].int()\n",
    "    print(topk(pred_probabilities_list[i],2))\n",
    "    class_idx = class_idx[1]\n",
    "    overlay_list_sec.append(getCAM(activated_features.features, weight_softmax, class_idx))\n",
    "    class_list_sec.append(class_idx)\n",
    "    activated_features.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(overlay_list_sec, class_list_sec)\n",
    "plot_images(lighthouse_image_list, description)\n",
    "plot_images_overlay(lighthouse_image_list, lighthouse_tensors ,overlay_list_sec, class_list_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-k4M4IdjQ0p"
   },
   "source": [
    "Second choice\n",
    "\n",
    "483: 'castle' [3.2850e-04]\n",
    "\n",
    "976: 'promontory, headland, head, foreland' [0.0701]\n",
    "\n",
    "975: 'lakeside, lakeshore', [0.0419]\n",
    "\n",
    "50: 'American alligator, Alligator mississipiensis',[0.0419]\n",
    "\n",
    "460: 'breakwater, groin, groyne, mole, bulwark, seawall, jetty', [0.0021]\n",
    "\n",
    "483: 'castle', [0.0043]\n",
    "\n",
    "497: 'church, church building', [2.8490e-04]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXXI8NGqjRCx"
   },
   "source": [
    "## Plot heatmap of other classes\n",
    "Lets check the heat map for some other classes \n",
    "\n",
    "*   527: 'desktop computer'\n",
    "*   587: 'hammer'\n",
    "*   497: 'church, church building',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJLNxnMyjRJY"
   },
   "outputs": [],
   "source": [
    "other_class = 497\n",
    "\n",
    "overlay_list_otherclass = []\n",
    "class_list_otherclass = []\n",
    "for i in range(len(lighthouse_tensors)):\n",
    "    input_image = prediction_var_list[i]\n",
    "    prediction = model(input_image) \n",
    "    class_idx = topk(prediction, 2)[1].int()\n",
    "    overlay_list_otherclass.append(getCAM(activated_features.features, weight_softmax, other_class))\n",
    "    \n",
    "    class_list_otherclass.append(torch.tensor(other_class, dtype=torch.int32))\n",
    "    activated_features.remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "jxeg7u0gjZx6",
    "outputId": "8be80318-c5e1-4504-f416-f29135e0537d"
   },
   "outputs": [],
   "source": [
    "plot_heatmap(overlay_list_otherclass, class_list_otherclass)\n",
    "plot_images(lighthouse_image_list, description)\n",
    "plot_images_overlay(lighthouse_image_list,\n",
    "                    lighthouse_tensors, overlay_list_otherclass, class_list_otherclass)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap of other classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probabilities_list_image = []\n",
    "\n",
    "for i in range(len(image_tensors)):\n",
    "    prediction = model(prediction_var_list_image[i])\n",
    "    pred_probabilities_list_image.append(F.softmax(prediction).data.squeeze())\n",
    "    activated_features.remove()\n",
    "\n",
    "print(\"Probability and predicted class:\")\n",
    "for i in range(len(image_tensors)):\n",
    "    probs = topk(pred_probabilities_list_image[i],1)\n",
    "    # print probabilities and predicted classes\n",
    "    print(class_name[probs[1].item()], probs[0].item())\n",
    "\n",
    "weight_softmax_params = list(model._modules.get('fc').parameters())\n",
    "weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy())\n",
    "\n",
    "overlay_list = []\n",
    "class_list = []\n",
    "for i in range(len(image_tensors)):\n",
    "    class_idx = topk(pred_probabilities_list_image[i],1)[1].int()\n",
    "    overlay_list.append(getCAM(activated_features.features, weight_softmax, class_idx))\n",
    "    class_list.append(class_idx)\n",
    "    activated_features.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(overlay_list, class_list)\n",
    "plot_images(image_list, image_name_list)\n",
    "plot_images_overlay(image_list, image_tensors, overlay_list, class_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "from captum.attr import LRP\n",
    "from captum.attr import visualization as viz\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError\n",
    "\n",
    "\n",
    "# Preprocessing and display_transform functions\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "display_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "threshold = 0.9\n",
    "\n",
    "\n",
    "# Process each image in the list\n",
    "for idx, input_image in enumerate(lighthouse_image_list):\n",
    "    preprocessed_image = preprocess(input_image).unsqueeze(0)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    output = model(preprocessed_image)\n",
    "    _, pred_class = torch.max(output, 1)\n",
    "    pred_class_idx = pred_class.item()\n",
    "\n",
    "    # Compute LRP attributions\n",
    "    lrp = LRP(model)\n",
    "    attributions = lrp.attribute(preprocessed_image, target=pred_class_idx)\n",
    "\n",
    "    # Visualize the attributions\n",
    "    attributions_np = attributions.squeeze().detach().numpy()\n",
    "    original_image_np = display_transform(input_image)\n",
    "    original_image_np = np.array(original_image_np) / 255.0\n",
    "\n",
    "    # Normalize the attributions\n",
    "    attributions_np = (attributions_np - np.min(attributions_np)) / (np.max(attributions_np) - np.min(attributions_np))\n",
    "\n",
    "    # Fix the flipped heatmap\n",
    "    attributions_np = np.flip(attributions_np, axis=2)\n",
    "\n",
    "    # Swap the axes of the attributions array\n",
    "    attributions_np = np.transpose(attributions_np, (1, 2, 0))\n",
    "\n",
    "    # Create a subplot for the original image and the heatmap\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(original_image_np)\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(attributions_np, cmap='viridis')\n",
    "    axs[1].set_title('Heatmap')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
